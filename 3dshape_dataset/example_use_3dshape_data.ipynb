{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c352c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085379cd",
   "metadata": {},
   "source": [
    "# Sample a dataset and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6523d1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set distributions of factors' values. If not specified, we will sample factors randomly\n",
    "dist={'shape': [1, 2, 1, 4],\n",
    "      'object_hue': [1, 1, 1, 2, 2, 3, 1, 3, 3, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec801aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a dataset and save\n",
    "sample_3dshape_dataset(dist, data_size=5000, save_name='example_set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8c00c1",
   "metadata": {},
   "source": [
    "# Use the sampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c5de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "872baf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _FACTORS_IN_ORDER = ['floor_hue', 'wall_hue', 'object_hue', 'scale', 'shape', 'orientation']\n",
    "# concept_interest is the indices of the interested factors that will be labels\n",
    "train_dataset = ShapesDataset(data_path='example_set.npy', concept_interest=[2,4], transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de2877d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "925f85a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee77e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f606990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e40d825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = train_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06c331da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 64, 64])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ede59f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3287f10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8000, 0.0000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63b5958",
   "metadata": {},
   "source": [
    "Or we use data_prefetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "111218f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_prefetcher():\n",
    "    def __init__(self, loader):\n",
    "        self.loader = iter(loader)\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.preload()\n",
    "\n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loader)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(non_blocking=True)\n",
    "            self.next_target = self.next_target.cuda(non_blocking=True)\n",
    "\n",
    "    def next(self):\n",
    "        torch.cuda.current_stream().wait_stream(self.stream)\n",
    "        input = self.next_input\n",
    "        target = self.next_target\n",
    "        if input is not None:\n",
    "            input.record_stream(torch.cuda.current_stream())\n",
    "        if target is not None:\n",
    "            target.record_stream(torch.cuda.current_stream())\n",
    "        self.preload()\n",
    "        return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97669761",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefetcher = data_prefetcher(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83e606f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, target = prefetcher.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2a73f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 64, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cb5adb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "093ed61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6000, 3.0000], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "465a675a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6000, 0.6000, 0.6000,  ..., 0.6000, 0.6000, 0.6000],\n",
       "         [0.6000, 0.6000, 0.6000,  ..., 0.6000, 0.6000, 0.6000],\n",
       "         [0.6000, 0.6000, 0.6000,  ..., 0.6000, 0.6000, 0.6000],\n",
       "         ...,\n",
       "         [0.2314, 0.2314, 0.2314,  ..., 0.1804, 0.1765, 0.1765],\n",
       "         [0.2275, 0.2275, 0.2275,  ..., 0.1804, 0.1804, 0.1765],\n",
       "         [0.2235, 0.2235, 0.2235,  ..., 0.1804, 0.1804, 0.1765]],\n",
       "\n",
       "        [[0.8863, 0.8863, 0.8863,  ..., 0.8863, 0.8863, 0.8863],\n",
       "         [0.8863, 0.8863, 0.8863,  ..., 0.8863, 0.8863, 0.8863],\n",
       "         [0.8863, 0.8863, 0.8863,  ..., 0.8863, 0.8863, 0.8863],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.9765, 0.9765, 0.9765,  ..., 0.9765, 0.9765, 0.9765],\n",
       "         [0.9765, 0.9765, 0.9765,  ..., 0.9765, 0.9765, 0.9765],\n",
       "         [0.9765, 0.9765, 0.9765,  ..., 0.9765, 0.9765, 0.9765],\n",
       "         ...,\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 0.8902, 0.8784, 0.8706],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 0.8902, 0.8824, 0.8745],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 0.8824, 0.8824, 0.8745]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677a0d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
